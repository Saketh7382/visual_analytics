{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3d799893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5ef8c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(X,y,batch_size=4):\n",
    "    loader = list()\n",
    "    points = len(X)\n",
    "    \n",
    "    i = 0\n",
    "    end = i + batch_size\n",
    "    batch = dict()\n",
    "    \n",
    "    batch[\"data\"] = X[i:end]\n",
    "    batch[\"output\"] = y[i:end]\n",
    "    loader.append(batch)\n",
    "    \n",
    "    while end < points:\n",
    "        i = i + batch_size\n",
    "        end = i + batch_size\n",
    "        \n",
    "        \n",
    "        batch = dict()\n",
    "        batch[\"data\"] = X[i:end]\n",
    "        batch[\"output\"] = y[i:end]\n",
    "        \n",
    "        loader.append(batch)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a9e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "33ed690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_total = pd.read_csv(\"./predictions/salesAnalyzer/total/store_{}.csv\".format(store))\n",
    "model2_total = model2_total.iloc[:-16,:]\n",
    "\n",
    "model3_total = pd.read_csv(\"./IBM_Cloud/predictions/model-1/predictions_total.csv\".format(store))\n",
    "model3_total = model3_total[model3_total[\"SCRUB_STORE_NO\"] == store].iloc[14:,:]\n",
    "\n",
    "training = pd.read_csv(\"./LSTM - Weather Sales Forecast/datasets/training.csv\")\n",
    "training = training[training[\"SCRUB_STORE_NO\"] == store].iloc[14:,:][\"SALES_UNITS\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e53851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = model2_total.iloc[:,-2:].copy()\n",
    "b = model3_total.iloc[:,-1:].copy()\n",
    "dataset[\"FORECAST_3\"] = b[\"predictions\"].to_numpy()\n",
    "dataset[\"ORIGINAL\"] = training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b789f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d1798051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1453, 3]) torch.Size([1453, 1])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor(np.array(x)))\n",
    "y = Variable(torch.Tensor(np.array(y)))\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d8effb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Composer(torch.nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Composer, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(3, n_hidden)   \n",
    "        self.predict = torch.nn.Linear(n_hidden, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      \n",
    "        x = self.predict(x)         \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6862480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([1163, 1, 3]) torch.Size([1163, 1])\n",
      "Testing Shape torch.Size([290, 1, 3]) torch.Size([290, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saketh/snap/jupyter/common/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 \t\t Training Loss: nan \t\t Validation Loss: nan\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-9e2ddc233ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d \\t\\t Training Loss: %1.5f \\t\\t Validation Loss: %1.5f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d \\t\\t Training Loss: %1.5f \\t\\t Validation Loss: %1.5f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_valid_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "train_split = 0.8\n",
    "\n",
    "rows = int(train_split*dataset.shape[0])\n",
    "\n",
    "x = dataset.iloc[:,:3].values\n",
    "y = dataset.iloc[:,3:].values\n",
    "\n",
    "X_train = x[:rows+1, :]\n",
    "X_test = x[rows+1:, :]\n",
    "\n",
    "y_train = y[:rows+1, :]\n",
    "y_test = y[rows+1:, :] \n",
    "\n",
    "data_X = Variable(torch.Tensor(np.array(x)))\n",
    "data_Y = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test)) \n",
    "\n",
    "data_X_tensors = torch.reshape(data_X,   (data_X.shape[0], 1, data_X.shape[1]))\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n",
    "\n",
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape) \n",
    "\n",
    "X_train,y_train,X_val,y_val = X_train_tensors_final, y_train_tensors, X_test_tensors_final, y_test_tensors\n",
    "\n",
    "train_loader = dataloader(X_train,y_train,batch_size=14)\n",
    "valid_loader = dataloader(X_val,y_val,batch_size=14)\n",
    "\n",
    "num_epochs = 1000 #1000 epochs\n",
    "learning_rate = 0.2 #0.001 lr\n",
    "\n",
    "n_hidden = 10 #number of features in hidden state\n",
    "\n",
    "net = Composer(n_hidden=10)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "current_threshold = 0\n",
    "cutoff_threshold = num_epochs/2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    '''---training---'''\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "\n",
    "    for i in train_loader:\n",
    "        data = i[\"data\"]\n",
    "        output = i[\"output\"]\n",
    "\n",
    "        outputs = net(data)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # obtain the loss function\n",
    "        loss = criterion(outputs, output)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    '''---validation---'''\n",
    "    valid_loss = 0.0\n",
    "    net.eval() \n",
    "\n",
    "    for i in valid_loader:\n",
    "        val_input = i[\"data\"]\n",
    "        val_output = i[\"output\"]\n",
    "\n",
    "        outputs = net(val_input)\n",
    "\n",
    "        loss = criterion(outputs,val_output)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    valid_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('Epoch %d \\t\\t Training Loss: %1.5f \\t\\t Validation Loss: %1.5f'%(epoch+1,train_loss,valid_loss))\n",
    "        \n",
    "    if min_valid_loss > valid_loss:\n",
    "        current_threshold = 0\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:1.5f}--->{valid_loss:1.5f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "\n",
    "        # Saving State Dict\n",
    "        torch.save(lstm.state_dict(), PATH)\n",
    "    else:\n",
    "        current_threshold += 1\n",
    "\n",
    "        if current_threshold == cutoff_threshold:\n",
    "            print(\"Stopping the training early\\t\\tModel saved\")\n",
    "            print(\"\\tTraining Loss: \",train_loss)\n",
    "            print(\"\\tValidation Loss: \",min_valid_loss)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM1(num_classes, input_size, hidden_size, num_layers)\n",
    "lstm.load_state_dict(torch.load(PATH))\n",
    "lstm.eval()\n",
    "\n",
    "\n",
    "train_predict = lstm(X_val)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = y_val.data.numpy()\n",
    "\n",
    "print(\"Shape of data_predict {}\".format(data_predict.shape))\n",
    "print(\"Shape of dataY_plot {}\".format(dataY_plot.shape))\n",
    "\n",
    "data_predict = mm.inverse_transform(data_predict)\n",
    "dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.axvline(x=rows, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Prediction')\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE of validation set: {}\".format(RMSE(data_predict,dataY_plot)))\n",
    "logger.log(\"RMSE of validation set: {}\".format(RMSE(data_predict,dataY_plot)))\n",
    "\n",
    "train_predict = lstm(data_X_tensors)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = data_y.data.numpy()\n",
    "\n",
    "data_predict = mm.inverse_transform(data_predict)\n",
    "dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "\n",
    "print(\"RMSE of entire data set: {}\".format(RMSE(data_predict,dataY_plot)))\n",
    "logger.log(\"RMSE of entire data set: {}\".format(RMSE(data_predict,dataY_plot)))\n",
    "\n",
    "logger.log(\"\\n\\n\\n\")\n",
    "logger.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "49cb3000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = Composer(n_hidden=10)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "for t in range(200):\n",
    "  \n",
    "    prediction = net(x)    \n",
    "\n",
    "    loss = loss_func(prediction, y)\n",
    "\n",
    "    optimizer.zero_grad()   \n",
    "    loss.backward()         \n",
    "    optimizer.step()        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6953be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d2648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
